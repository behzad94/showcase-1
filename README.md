# ğŸ§  Document Information Agent (RAG Showcase)

This project is the **Showcase 1** implementation for the *AI & Interactive Technologies* course.  
It demonstrates a local **Retrieval-Augmented Generation (RAG)** pipeline powered by a local LLM (Ollama phi3).

---

## âš™ï¸ Architecture Overview

| Stage | Description |
|--------|--------------|
| **Ingest** | Loads PDF / TXT / MD files â†’ detects encoding â†’ extracts text. |
| **Chunk** | Splits into ~500-token chunks with 50 token overlap. |
| **Embed** | Uses `sentence-transformers/all-MiniLM-L6-v2` (normalized vectors). |
| **Store** | Saves vectors in **FAISS (IP)** index + manifest JSON. |
| **Retrieve** | Hybrid dense retrieval + small keyword overlap boost. |
| **Answer** | RAG pipeline with optional **Ollama phi3** summarization, clarifications, and citation-audit logic. |
| **API** | FastAPI backend exposing `/ask` and `/rebuild_index`. |
| **UI** | Streamlit interface with transparency & GDPR notice. |

---

## ğŸš€ Quick Start

```bash
# 1ï¸âƒ£ Install dependencies
python -m pip install -r requirements.txt

# 2ï¸âƒ£ (Optional) create and activate virtual env
python3 -m venv .venv
source .venv/bin/activate   # macOS / Linux

# 3ï¸âƒ£ Start backend API
uvicorn src.api.server:app --reload-dir src

# 4ï¸âƒ£ Launch Streamlit UI
streamlit run src/ui/app.py
```

Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ğŸ§© Local LLM (Ollama)

This showcase runs **fully locally** for data-privacy reasons.

```bash
ollama serve
ollama pull phi3:latest
```

The summarizer connects to
`http://127.0.0.1:11434/api/chat` using `phi3:latest`.

---

## ğŸ“ Folder Structure

```
showcase1-rag/
â”œâ”€â”€ corpus/           # user documents (PDF/TXT/MD)
â”œâ”€â”€ data/processed/   # FAISS index + manifest
â”œâ”€â”€ logs/             # JSONL audit logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/server.py
â”‚   â”œâ”€â”€ ingest/, chunk/, embed/, search/, store/, answer/
â”‚   â””â”€â”€ ui/app.py
â”œâ”€â”€ run.sh            # unified launcher script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§¾ Transparency & Ethics

* The system operates **offline**, no external API calls.
* Citations and confidence checks are provided for transparency.
* Users must review outputs before making impactful decisions (GDPR Art. 22).

---

## ğŸ§ª One-Command Run

```bash
./run.sh
```

This script:

1. Activates `.venv`
2. Installs dependencies if missing
3. Checks Ollama + model
4. Starts FastAPI backend
5. Launches Streamlit UI
6. Cleans up on exit

---

## ğŸ§‘â€ğŸ’» Author

**Behzad Moloudi** â€” Turku UAS, 2025

```